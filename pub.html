<!--
Author: W3layouts
Author URL: http://w3layouts.com
License: Creative Commons Attribution 3.0 Unported
License URL: http://creativecommons.org/licenses/by/3.0/
-->

<!DOCTYPE html>
<html lang="zxx">

<head>
    <title>Fenggen Yu's publication</title>
    <!-- Meta tag Keywords -->
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <meta charset="UTF-8" />
    <script>
        addEventListener("load", function() {
            setTimeout(hideURLbar, 0);
        }, false);

        function hideURLbar() {
            window.scrollTo(0, 1);
        }

    </script>
    <!-- //Meta tag Keywords -->
    <!-- Custom-Files -->
    <link rel="stylesheet" href="css/bootstrap.css">
    <!-- Bootstrap-Core-CSS -->
    <link rel="stylesheet" href="css/style.css" type="text/css" media="all" />
    <link rel="stylesheet" href="css/slider.css" type="text/css" media="all" />
    <!-- Style-CSS -->
    <!-- font-awesome-icons -->
    <link href="css/font-awesome.css" rel="stylesheet">
    <!-- //font-awesome-icons -->
    <!-- /Fonts -->
    <link href="//fonts.googleapis.com/css?family=Catamaran:100,200,300,400,500,600,700,800" rel="stylesheet">

    <!-- //Fonts -->
</head>

<body>
	<!-- mian-content -->
    <div class="main-w3-pvt-header-sec page-w3pvt-inner" id="home">

        <!-- header -->
        <header>
            <div class="container">
                <div class="header d-lg-flex justify-content-between align-items-center py-lg-3 px-lg-3">
                    <!-- logo -->
                    <div id="logo">
                        <h1><a href="index.html">Fenggen Yu</a></h1>
                    </div>
                    <!-- //logo -->
                    <div class="w3pvt-bg">
                        <!-- nav -->
                        <div class="nav_w3pvt">
                            <nav>
                                <label for="drop" class="toggle">Menu</label>
                                <input type="checkbox" id="drop" />
                                <ul class="menu">
                                    <li><a href="index.html">Home</a></li>
                                    <li><a href="bio.html">Bio & cv</a></li>
                                    <li class="active"><a href="pub.html">Publications</a></li>
                                    <li><a href="contact.html">Contact Me</a></li>
                                </ul>
                            </nav>
                        </div>
                    </div>
                </div>
            </div>
        </header>
        <!-- //header -->
        <!-- //slider -->
    </div>
	
    <!-- /features -->
    <section class="about py-md-5 py-5" id="loans">
		
        <div class="container py-md-5">
			<h3>Publications</h3>
            <div class="feature-grids row mt-3">
                <div class="col-lg-4 ab-content-img">
                    <img src="images/CAPRI.png" alt="" class="img-fluid image1">
                </div>
                <div class="col-lg-8 ab-content-inf pl-lg-5">
					<h3 class="mb-3 wthree_title"><strong>Fenggen Yu</strong>, <a href="https://czq142857.github.io/">Zhiqin Chen</a>, <a href="https://manyili12345.github.io/">Manyi Li</a>, Aditya Sanghi, Hooman Shayani, <a href="https://sites.google.com/site/alimahdaviamiri/">Ali Mahdavi-Amiri</a> and <a href="https://www.cs.sfu.ca/~haoz/">Hao(Richard) Zhang</a>.</h3>
                    <h3 class="mb-3 wthree_title">CAPRI-Net: Learning Compact CAD Shapes with Adaptive Primitive Assembly.</h3>
                    <h3 class="mb-3 wthree_title"><a href="https://arxiv.org/abs/2104.05652">[Paper]</a>, <a href="capri.html">[Project Page]</a>, Accepted to <a href="https://cvpr2022.thecvf.com/">[CVPR 2022]</a> </h3>
                    
					<p>We introduce CAPRI-Net, a neural network for learning compact and interpretable implicit representations of 3D computer-aided design (CAD) models, in the form of adaptive primitive assemblies.</p>
                    
                </div>
			</div>

            <div class="feature-grids row mt-3">
                <div class="col-lg-4 ab-content-img">
                    <img src="images/RaidaR.png" alt="" class="img-fluid image1">
                </div>
                <div class="col-lg-8 ab-content-inf pl-lg-5">
					<h3 class="mb-3 wthree_title">Jiongchao Jin, Arezou Fatemi, Wallace Lira, <strong>Fenggen Yu</strong>, Biao Leng, <a href="https://maruitx.github.io/">Rui Ma</a>, <a href="https://sites.google.com/site/alimahdaviamiri/">Ali Mahdavi-Amiri</a> and <a href="https://www.cs.sfu.ca/~haoz/">Hao(Richard) Zhang</a>.</h3>
                    <h3 class="mb-3 wthree_title">RaidaR: A Rich Annotated Image Dataset of Rainy Street Scenes.</h3>
                    <h3 class="mb-3 wthree_title"><a href="https://arxiv.org/abs/2104.04606">[Paper]</a>, Second ICCV Workshop on Autonomous Vehicle Vision (AVVision), 2021</h3>
                    
					<p>We introduce RaidaR, a rich annotated image dataset of rainy street scenes, to support autonomous driving research. The new dataset contains the largest number of rainy images (58,542) to date, 5,000 of which provide semantic segmentations and 3,658 provide object instance segmentations.</p>
                    
                </div>
			</div>
			
			<div class="feature-grids row mt-3">
                <div class="col-lg-4 ab-content-img">
                    <img src="images/VDAC.png" alt="" class="img-fluid image1">
                </div>
                <div class="col-lg-8 ab-content-inf pl-lg-5">
					<h3 class="mb-3 wthree_title"><a href="https://sites.google.com/site/alimahdaviamiri/">Ali Mahdavi-Amiri</a>, <strong>Fenggen Yu</strong>, <a href="https://homes.cs.washington.edu/~haisen/">Haisen Zhao</a>, <a href="https://homes.cs.washington.edu/~adriana/">Adriana Schulz</a> and <a href="https://www.cs.sfu.ca/~haoz/">Hao(Richard) Zhang</a>.</h3>
                    <h3 class="mb-3 wthree_title">VDAC: Volume Decompose-and-Carve for Subtractive Manufacturing.</h3>
                    <h3 class="mb-3 wthree_title">Accepted to <a href="https://sa2020.siggraph.org/en/">SIGGRAPH ASIA 2020</a>|<a href="https://drive.google.com/file/d/1TOxxNuAeYSceriNUQnvACm_oxFEo_kF3/view">[Paper]</a>|<a href="https://sites.google.com/site/alimahdaviamiri/projects/vdac?authuser=0">[Project page]</a></h3>
                    
					<p>We introduce carvable volume decomposition for efficient 3-axis CNC machining of 3D freeform objects, where our goal is to develop a fully automatic method to jointly optimize setup and path planning.</p>
                    
                </div>
			</div>
            <div class="feature-grids row mt-3">
                <div class="col-lg-4 ab-content-img">
                    <img src="images/proj1.jpg" alt="" class="img-fluid image1">
                </div>
                <div class="col-lg-8 ab-content-inf pl-lg-5">
					<h3 class="mb-3 wthree_title"><strong>Fenggen Yu</strong>, Kun Liu, <a href="https://cs.nju.edu.cn/zhangyan/">Yan Zhang</a>, <a href="http://www.sfu.ca/~cza68/">Chenyang Zhu</a>, <a href="http://kevinkaixu.net/index.html">Kai Xu</a>.</h3>
                    <h3 class="mb-3 wthree_title">PartNet: A Recursive Part Decomposition Network for Fine-grained and Hierarchical Shape Segmentation.</h3>
                    <h3 class="mb-3 wthree_title">Accepted to <a href="cvpr2019.thecvf.com/">CVPR 2019</a>|<a href="https://arxiv.org/abs/1903.00709">[Paper]</a>|<a href="https://github.com/FoggYu/PartNet">[Code & data]</a></h3>
                    
					<p>Deep learning approaches to 3D shape segmentation are typically formulated as a multi-class labeling problem. Existing models are trained for a fixed set of labels, which greatly limits their flexibility and adaptivity. We opt for topdown recursive decomposition and develop the first deep learning model for hierarchical segmentation of 3D shapes, based on recursive neural networks.</p>
                    
                </div>
			</div>
			<div class="feature-grids row mt-3">
				<div class="col-lg-4 ab-content-img">
                    <img src="images/proj2.jpg" alt="" class="img-fluid image1">
                </div>
                <div class="col-lg-8 ab-content-inf pl-lg-5">
					<h3 class="mb-3 wthree_title"><strong>Fenggen Yu</strong>, <a href="https://cs.nju.edu.cn/zhangyan/">Yan Zhang</a>, <a href="http://kevinkaixu.net/index.html">Kai Xu</a>, <a href="https://sites.google.com/site/alimahdaviamiri/">Ali Mahdavi-Amiri</a> and <a href="https://www.cs.sfu.ca/~haoz/">Hao(Richard) Zhang</a>.</h3>
                    <h3 class="mb-3 wthree_title">Semi-Supervised Co-Analysis of 3D Shape Styles from Projected Lines.</h3>
                    <h3 class="mb-3 wthree_title">Accepted to <a href="https://tog.acm.org/">ACM Transactions on Graphics</a> (to be presented at SIGGRAPH 2018), 37(2)|<a href="https://arxiv.org/abs/1804.06579">[Paper]</a>|<a href="https://github.com/FoggYu/proj_style">[Code & data]</a>.</h3>
                    
					<p>We present a semi-supervised co-analysis method for learning 3D shape styles from projected feature lines, achieving style patch localization with only weak supervision. Given a collection of 3D shapes spanning multiple object categories and styles, we perform style co-analysis over projected feature lines of each 3D shape and then backproject the learned style features onto the 3D shapes.</p>
                </div>
			</div>
			
			<div class="feature-grids row mt-3">
				<div class="col-lg-4 ab-content-img">
                    <img src="images/proj4.jpg" alt="" class="img-fluid image1">
                </div>
                <div class="col-lg-8 ab-content-inf pl-lg-5">
					<h3 class="mb-3 wthree_title">PanPan Shui, Pengyu Wang, <strong>Fenggen yu</strong>, Bingyang Hu, Yuan Gan, Kun Liu, <a href="https://cs.nju.edu.cn/zhangyan/">Yan Zhang</a>.</h3>
                    <h3 class="mb-3 wthree_title">3D Shape Segmentation Based on Viewpoint Entropy and Projective Fully Convolutional Networks Fusing Multi-view Features.</h3>
                    <h3 class="mb-3 wthree_title">Accepted to <a href="http://www.icpr2018.net/">ICPR 2018</a>|<a href="https://www.researchgate.net/publication/329316036_3D_Shape_Segmentation_Based_on_Viewpoint_Entropy_and_Projective_Fully_Convolutional_Networks_Fusing_Multi-view_Features">[Paper]</a>.</h3>
                    
					<p>This paper introduces an architecture for segmenting 3D shapes into labeled semantic parts. Our architecture
					combines viewpoint selection method based on viewpoint entropy,
					multi-view image-based Fully Convolutional Networks (FCNs)
					and graph cuts optimization method to yield coherent segmentation of 3D shapes. </p>
                </div>
			</div>
			
			<div class="feature-grids row mt-3">
				<div class="col-lg-4 ab-content-img">
                    <img src="images/proj3.jpg" alt="" class="img-fluid image1">
                </div>
                <div class="col-lg-8 ab-content-inf pl-lg-5">
					<h3 class="mb-3 wthree_title">Pengyu Wang*, Yuan Gan*, Panpan Shui, <strong>Fenggen Yu</strong>, <a href="https://cs.nju.edu.cn/zhangyan/">Yan Zhang</a>, Songle Chen, <a href="https://cs.nju.edu.cn/sunzhx/">Zhengxing Sun</a>.</h3>
                    <h3 class="mb-3 wthree_title">3D Shape Segmentation via Shape Fully Convolutional Networks.</h3>
                    <h3 class="mb-3 wthree_title">Accepted to <a href="https://www.journals.elsevier.com/computers-and-graphics">Computer & Graphics</a>, Vol 70, Feb 2018.|<a href="https://arxiv.org/pdf/1702.08675.pdf">[Paper]</a>|<a href="https://github.com/yuangan/3D-Shape-Segmentation-via-Shape-Fully-Convolutional-Networks">[Code & data]</a>.</h3>
                    
					<p>We design a novel fully convolutional network architecture for shapes, denoted by Shape Fully Convolutional Networks (SFCN). 3D shapes are represented as graph structures in the SFCN architecture, based on novel graph convolution and pooling operations, which are similar to convolution and pooling operations used on images. </p>
                </div>
			</div>
        </div>
    </section>

    <!-- //footer -->
    <div class="copy-right">
        <div class="container">
            <div class="row">
				<p class="copy-right-grids text-md-left text-center my-sm-4 my-4 col-md-6">Â© All Rights Reserved | Designed by Fenggen Yu</p>
				<div class="w3-pvt-footer text-md-right text-center mt-4 col-md-5">
                    <ul class="list-unstyled w3-pvt-icons">
                        <li>
                            <a href="https://twitter.com/fenggenyu">
                                <span class="fa fa-twitter"></span>
                            </a>
                        </li>
                    </ul>
                </div>
                <div class="move-top text-right col-md-1"><a href="#home" class="move-top"> <span class="fa fa-angle-up  mb-3" aria-hidden="true"></span></a></div>

            </div>
        </div>
    </div>
</body>

</html>
